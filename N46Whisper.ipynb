{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEAvBF4zgXX4"
      },
      "source": [
        "# N46Whisper\n",
        "\n",
        "N46Whisper is a Google Colab notebook application for streamlined video subtitle file generation.The original purpose of the project was to improve the productivity of Nogizaka46 (and Sakamichi groups) subbers. However, it can also be used to create subtitles in general.The application could significantly reduce the labour and time costs of sub-groups or individual subbers. However, despite its impressive performance, the Whisper model, AI translation and the application itself are not without limitations.\n",
        "\n",
        "\n",
        "N46Whisper 是基于 Google Colab 的应用。开发初衷旨在提高乃木坂46（以及坂道系）字幕组日语视频的制作效率,但亦适于所有外语视频的字幕制作。本应用的目标并非生产完美的字幕文件， 而旨在于搭建并提供一个简单且自动化的使用平台以节省生产成品字幕的时间和精力。Whisper模型有其本身的应用场景限制，AI 翻译的质量亦还不能尽如人意。\n",
        "\n",
        "<font size='4'>**对于中文用户，推荐在使用前阅读[常见问题说明](https://github.com/Ayanaminn/N46Whisper/blob/main/FAQ.md)。如果你觉得本应用对你有所帮助，欢迎帮助扩散给更多的人。**\n",
        "\n",
        "\n",
        "<font size='4'>**联系作者/Contact me：[E-mail](admin@ikedateresa.cc)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZ2x8S7RMF9i"
      },
      "source": [
        "## 更新/What's Latest：\n",
        "历史更新日志\n",
        "\n",
        "<font size = '3'>**本项目将不再进行维护和更新，感谢大家的帮助与支持。**\n",
        "</br></br>\n",
        "\n",
        "2024.4.17:\n",
        "* 添加使用Google Gemini API翻译的选项。\n",
        "\n",
        "2024.1.31:\n",
        "* 鉴于集成的参数选项（还会）越来越多有使流程变得繁琐的趋势，这有违开发初衷。因此测试分离了一个[轻量版](https://colab.research.google.com/github/Ayanaminn/N46Whisper/blob/dev/N46WhisperLite.ipynb)，只保留最少的必要操作。\n",
        "\n",
        "2023.12.4:\n",
        "* 支持基于faster-whisper的WhisperV3模型/Support faster-whisper based WhisperV3 model\n",
        "\n",
        "2023.11.7:\n",
        "* 现在可以加载最新的WhisperV3模型/Enable users to load lastest Whisper V3 model.\n",
        "* 允许用户自行设置beam size/ Enable customerize beam size parameter.\n",
        "\n",
        "2023.4.30:\n",
        "* 优化提示词/Refine the translation prompt.\n",
        "* 允许用户使用个人提示词并调节Temperature参数/Allow user to custom prompt and temperature for translation.\n",
        "* 显示翻译任务消费统计/Display the token used and total cost for the translation task.\n",
        "\n",
        "2023.4.15:\n",
        "* 使用faster-whisper模型重新部署以提高效率，节省资源。Reimplement Whsiper based on faster-whsiper to improve efficiency.\n",
        "* 提供faster-whisper集成的vad filter选项以提高转录精度。Enable vad filter that integrated in faster-whisper to improve transcribe accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laXaXrgPvCOn"
      },
      "source": [
        "**<font size='5'>以下选择文件方式按需执行其中一种即可，不需要全部运行</font>**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U gdown\n",
        "import gdown\n",
        "\n",
        "# 用 gdown 下载共享文件\n",
        "file_id = \"1w7ZYbHv2mRNBOH0r0JkGvAZcrKkEZCMF\"\n",
        "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", output=\"downloaded_file\", quiet=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "VzXyaCg42oNe",
        "outputId": "a461887c-a7c0-4eb4-f992-48c958212476"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.4.26)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1w7ZYbHv2mRNBOH0r0JkGvAZcrKkEZCMF\n",
            "To: /content/downloaded_file\n",
            "100%|██████████| 50.0M/50.0M [00:00<00:00, 55.9MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'downloaded_file'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8kquVjWvh6c"
      },
      "source": [
        "**<font size='5'>以下顺次点击下方每个单元格左侧的“运行”图标，不可跳过步骤</font>**\n",
        "**</br>【重要】:** 务必在\"修改\"->\"笔记本设置\"->\"硬件加速器\"中选择GPU！否则处理速度会非常慢。\n",
        " **</br>【IMPORTANT】:** Make sure you select GPU as hardware accelerator in notebook settings, otherwise the processing speed will be very slow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "z0igG7ruI-7q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "b0f8fc1c-ad5f-45f7-b567-df1c41d54562"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "准备识别模型 Ready to run Whisper...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "识别中 Transcribe in progress...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|████████▉ | 11152.639999999914/12499.03 [20:38<02:29,  9.00 seconds/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ce4096ad-4e79-4e2e-9ce9-51cc11930ebd\", \"downloaded_file.srt\", 68801)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 字幕生成完毕！耗时 1277.41 秒\n"
          ]
        }
      ],
      "source": [
        "# 安装依赖（如果之前已装可注释）\n",
        "!pip install ffmpeg pysubs2 faster-whisper ctranslate2==4.4.0\n",
        "!wget https://raw.githubusercontent.com/Ayanaminn/N46Whisper/main/srt2ass.py\n",
        "\n",
        "# 系统依赖\n",
        "!apt remove --purge -y libcudnn9 libcudnn9-dev\n",
        "!apt autoremove -y\n",
        "!apt update\n",
        "!apt install -y libcudnn8 libcudnn8-dev\n",
        "\n",
        "import torch\n",
        "from faster_whisper import WhisperModel\n",
        "from IPython.display import clear_output\n",
        "import os, time, pysubs2, zipfile\n",
        "from tqdm import tqdm\n",
        "from google.colab import files\n",
        "from pathlib import Path\n",
        "from srt2ass import srt2ass\n",
        "\n",
        "clear_output()\n",
        "print('准备识别模型 Ready to run Whisper...')\n",
        "\n",
        "# 使用指定文件\n",
        "file_path = \"downloaded_file\"\n",
        "\n",
        "\n",
        "# 转写文件名基础\n",
        "file_basename = Path(file_path).stem\n",
        "output_dir = Path(file_path).parent.resolve()\n",
        "\n",
        "\n",
        "# 加载模型\n",
        "model = WhisperModel('large-v3')\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "print('识别中 Transcribe in progress...')\n",
        "tic = time.time()\n",
        "\n",
        "segments, info = model.transcribe(\n",
        "    audio=\"downloaded_file\",\n",
        "    language='ja',\n",
        "    vad_filter=False,\n",
        "    beam_size=3,\n",
        "    vad_parameters={\"min_silence_duration_ms\": 200}\n",
        ")\n",
        "\n",
        "# 解析 segments\n",
        "total_duration = round(info.duration, 2)\n",
        "results = []\n",
        "with tqdm(total=total_duration, unit=\" seconds\") as pbar:\n",
        "    for s in segments:\n",
        "        segment_dict = {'start': s.start, 'end': s.end, 'text': s.text}\n",
        "        results.append(segment_dict)\n",
        "        pbar.update(s.end - s.start)\n",
        "\n",
        "# 输出 SRT\n",
        "srt_filename = 'false-3-200' + \".srt\"\n",
        "subs = pysubs2.load_from_whisper(results)\n",
        "subs.save(srt_filename)\n",
        "\n",
        "\n",
        "\n",
        "# 下载文件\n",
        "\n",
        "files.download(srt_filename)\n",
        "\n",
        "\n",
        "toc = time.time()\n",
        "print(f\"✅ 字幕生成完毕！耗时 {toc - tic:.2f} 秒\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "k5n2xrB631JV"
      },
      "outputs": [],
      "source": [
        "#@title **【实验功能】Experimental Features:**\n",
        "\n",
        "# @markdown **AI文本翻译/AI Translation:**\n",
        "# @markdown **</br>**<font size=\"2\"> 此功能允许用户使用AI翻译服务对识别的字幕文件做逐行翻译，并以相同的格式生成双语对照字幕。\n",
        "# @markdown **</br>**阅读项目文档以了解更多。</font>\n",
        "# @markdown **</br>**<font size=\"2\"> This feature allow users to translate previously transcribed subtitle text line by line using AI translation.\n",
        "# @markdown **</br>**Then generate bilingual subtitle files in same sub style.Read documentaion to learn more.</font>\n",
        "\n",
        "# @markdown **</br>**希望在本地使用字幕翻译功能的用户，推荐尝试 [subtitle-translator-electron](https://github.com/gnehs/subtitle-translator-electron)\n",
        "\n",
        "# @markdown **</br><font size=\"3\">Select subtitle file source</br>\n",
        "# @markdown <font size=\"3\">选择字幕文件(使用上一步的转录-use_transcribed/新上传-upload_new）</br>**\n",
        "# @markdown <font size=\"2\">支持SRT与ASS文件\n",
        "sub_source = \"upload_new\"  # @param [\"use_transcribed\",\"upload_new\"]\n",
        "\n",
        "# @markdown **chatGPT:**\n",
        "# @markdown **</br>**<font size=\"2\"> 要使用chatGPT翻译，请填入你自己的OpenAI API Key，目标语言，输出类型，然后执行单元格。</font>\n",
        "# @markdown **</br>**<font size=\"2\"> Please input your own OpenAI API Key, then execute this cell.</font>\n",
        "# @markdown **</br>**<font size=\"2\">【注意】 免费的API对速度有所限制，需要较长时间，用户可以自行考虑付费方案。</font>\n",
        "# @markdown **</br>**<font size=\"2\">【Note】There are limitaions on usage for free API, consider paid plan to speed up.</font>\n",
        "openai_key = '' # @param {type:\"string\"}\n",
        "target_language = 'zh-hans'# @param [\"zh-hans\",\"english\"]\n",
        "prompt = \"You are a language expert.Your task is to translate the input subtitle text, sentence by sentence, into the user specified target language.However, please utilize the context to improve the accuracy and quality of translation.Please be aware that the input text could contain typos and grammar mistakes, utilize the context to correct the translation.Please return only translated content and do not include the origin text.Please do not use any punctuation around the returned text.Please do not translate people's name and leave it as original language.\\\"\" # @param {type:\"string\"}\n",
        "temperature = 0.6 #@param {type:\"slider\", min:0, max:1.0, step:0.1}\n",
        "# @markdown <font size=\"4\">Default prompt: </br>\n",
        "# @markdown ```You are a language expert.```</br>\n",
        "# @markdown ```Your task is to translate the input subtitle text, sentence by sentence, into the user specified target language.```</br>\n",
        "# @markdown ```Please utilize the context to improve the accuracy and quality of translation.```</br>\n",
        "# @markdown ```Please be aware that the input text could contain typos and grammar mistakes, utilize the context to correct the translation.```</br>\n",
        "# @markdown ```Please return only translated content and do not include the origin text.```</br>\n",
        "# @markdown ```Please do not use any punctuation around the returned text.```</br>\n",
        "# @markdown ```Please do not translate people's name and leave it as original language.```</br>\n",
        "output_format = \"ass\"  # @param [\"ass\",\"srt\"]\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import codecs\n",
        "import regex as re\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from google.colab import files\n",
        "from IPython.display import clear_output\n",
        "\n",
        "clear_output()\n",
        "\n",
        "if sub_source == 'upload_new':\n",
        "  uploaded = files.upload()\n",
        "  sub_name = list(uploaded.keys())[0]\n",
        "  sub_basename = Path(sub_name).stem\n",
        "elif sub_source == 'use_transcribed':\n",
        "  sub_name = file_basenames[0] +'.ass'\n",
        "  sub_basename = file_basenames[0]\n",
        "\n",
        "!pip install openai\n",
        "!pip install pysubs2\n",
        "from openai import OpenAI\n",
        "import pysubs2\n",
        "\n",
        "clear_output()\n",
        "\n",
        "class ChatGPTAPI():\n",
        "    def __init__(self, key, language, prompt, temperature):\n",
        "        self.key = key\n",
        "        # self.keys = itertools.cycle(key.split(\",\"))\n",
        "        self.language = language\n",
        "        self.key_len = len(key.split(\",\"))\n",
        "        self. prompt = prompt\n",
        "        self.temperature = temperature\n",
        "\n",
        "\n",
        "    # def rotate_key(self):\n",
        "    #     openai.api_key = next(self.keys)\n",
        "\n",
        "    def translate(self, text):\n",
        "        # print(text)\n",
        "        # self.rotate_key()\n",
        "        client = OpenAI(\n",
        "            api_key=self.key,\n",
        "            )\n",
        "\n",
        "        try:\n",
        "            completion = client.chat.completions.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"system\",\n",
        "                        # english prompt here to save tokens\n",
        "                        \"content\": f'{self.prompt}'\n",
        "                    },\n",
        "                    {\n",
        "                        \"role\":\"user\",\n",
        "                        \"content\": f\"Original text:`{text}`. Target language: {self.language}\"\n",
        "                    }\n",
        "                ],\n",
        "                temperature=self.temperature\n",
        "            )\n",
        "            t_text = (\n",
        "                completion.choices[0].message.content.encode(\"utf8\").decode()\n",
        "            )\n",
        "            total_tokens = completion.usage.total_tokens # include prompt_tokens and completion_tokens\n",
        "        except Exception as e:\n",
        "            # TIME LIMIT for open api , pay to reduce the waiting time\n",
        "            sleep_time = int(60 / self.key_len)\n",
        "            time.sleep(sleep_time)\n",
        "            print(e, f\"will sleep  {sleep_time} seconds\")\n",
        "            # self.rotate_key()\n",
        "            client = OpenAI(\n",
        "            api_key=self.key,\n",
        "            )\n",
        "            completion = client.chat.completions.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"system\",\n",
        "                        \"content\": f'{self.prompt}'\n",
        "                    },\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": f\"Original text:`{text}`. Target language: {self.language}\"\n",
        "                    }\n",
        "                ],\n",
        "                temperature=self.temperature\n",
        "            )\n",
        "            t_text = (\n",
        "                completion.choices[0].message.content.encode(\"utf8\").decode()\n",
        "            )\n",
        "        total_tokens = completion.usage.total_tokens\n",
        "        return t_text, total_tokens\n",
        "\n",
        "\n",
        "class SubtitleTranslator():\n",
        "    def __init__(self, sub_src, model, key, language, prompt,temperature):\n",
        "        self.sub_src = sub_src\n",
        "        self.translate_model = model(key, language,prompt,temperature)\n",
        "        self.translations = []\n",
        "        self.total_tokens = 0\n",
        "\n",
        "    def calculate_price(self,num_tokens):\n",
        "        price_per_token = 0.000002 #gpt-3.5-turbo\t$0.002 / 1K tokens\n",
        "        return num_tokens * price_per_token\n",
        "\n",
        "    def translate_by_line(self):\n",
        "        sub_trans = pysubs2.load(self.sub_src)\n",
        "        total_lines = len(sub_trans)\n",
        "        for line in tqdm(sub_trans,total = total_lines):\n",
        "            line_trans, tokens_per_task = self.translate_model.translate(line.text)\n",
        "            line.text += (r'\\N'+ line_trans)\n",
        "            print(line_trans)\n",
        "            self.translations.append(line_trans)\n",
        "            self.total_tokens += tokens_per_task\n",
        "\n",
        "        return sub_trans, self.translations, self.total_tokens\n",
        "\n",
        "\n",
        "clear_output()\n",
        "\n",
        "translate_model = ChatGPTAPI\n",
        "\n",
        "assert translate_model is not None, \"unsupported model\"\n",
        "OPENAI_API_KEY = openai_key\n",
        "\n",
        "if not OPENAI_API_KEY:\n",
        "    raise Exception(\n",
        "        \"OpenAI API key not provided, please google how to obtain it\"\n",
        "    )\n",
        "# else:\n",
        "#     OPENAI_API_KEY = openai_key\n",
        "\n",
        "t = SubtitleTranslator(\n",
        "    sub_src=sub_name,\n",
        "    model= translate_model,\n",
        "    key = OPENAI_API_KEY,\n",
        "    language=target_language,\n",
        "    prompt=prompt,\n",
        "    temperature=temperature)\n",
        "\n",
        "translation, _, total_token = t.translate_by_line()\n",
        "total_price = t.calculate_price(total_token)\n",
        "#Download ass file\n",
        "\n",
        "if output_format == 'ass':\n",
        "  translation.save(sub_basename + '_translation.ass')\n",
        "  files.download(sub_basename + '_translation.ass')\n",
        "elif output_format == 'srt':\n",
        "  translation.save(sub_basename + '_translation.srt')\n",
        "  files.download(sub_basename + '_translation.srt')\n",
        "\n",
        "\n",
        "\n",
        "print('双语字幕生成完毕 All done!')\n",
        "print(f\"Total number of tokens used: {total_token}\")\n",
        "print(f\"Total price (USD): ${total_price:.4f}\")\n",
        "\n",
        "# @markdown **</br>**<font size='3'>**实验功能的开发亦是为了尝试帮助大家更有效率的制作字幕。但是只有在用户实际使用体验反馈的基础上，此应用才能不断完善，如果您有任何想法，都欢迎以任何方式联系我，提出[issue](https://github.com/Ayanaminn/N46Whisper/issues)或者分享在[讨论区](https://github.com/Ayanaminn/N46Whisper/discussions)。**\n",
        "# @markdown **</br>**<font size='3'>**The efficacy of this application cannot get improved without the feedbacks from everyday users.Please feel free to share your thoughts with me or post it [here](https://github.com/Ayanaminn/N46Whisper/discussions)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "52JugZiQMQUm"
      },
      "outputs": [],
      "source": [
        "#@title **【实验功能】Experimental Features:**\n",
        "\n",
        "# @markdown **Google Gemini AI文本翻译/Google Gemini AI Translation:**\n",
        "# @markdown **</br>**<font size=\"2\"> 由于谷歌Gemini提供免费的API，想要免费使用AI翻译的用户可以执行该单元格。\n",
        "# @markdown **</br>**阅读项目文档以了解更多。</font>\n",
        "# @markdown **</br>**<font size=\"2\"> Since Google Gemini provides a free tier API, the users that want to use free AI translations can execute this block of code.\n",
        "# @markdown **</br>**Then generate bilingual subtitle files in same sub style.Read documentaion to learn more.</font>\n",
        "\n",
        "# @markdown **注意：同时执行Whisper翻译和Gemini API翻译有可能遇到runtime问题，建议在disconnect runtime之后重新执行该单元格**\n",
        "\n",
        "# @markdown **Attention: Executing Whisper and Gemini translation at the same time might run into runtime errors, we recommend that the users disconnect their runtimes before executing this block**\n",
        "output_format = \"ass\"  # @param [\"ass\",\"srt\"]\n",
        "\n",
        "# @markdown **Google Gemini:**\n",
        "# @markdown **</br>**<font size=\"2\"> 要使用Gemini翻译，请填入你自己的Gemini API Key，目标语言，输出类型，然后执行单元格。</font>\n",
        "# @markdown **</br>**<font size=\"2\"> Please input your own Gemini API Key, then execute this cell.</font>\n",
        "\n",
        "google_api_key = '' # @param {type:\"string\"}\n",
        "target_language = 'zh-hans'# @param [\"zh-hans\",\"english\"]\n",
        "prompt = \"You are a language expert.Your task is to translate the input subtitle text, sentence by sentence, into the user specified target language.However, please utilize the context to improve the accuracy and quality of translation.Please be aware that the input text could contain typos and grammar mistakes, utilize the context to correct the translation.Please return only translated content and do not include the origin text.Please do not use any punctuation around the returned text.Please do not translate people's name and leave it as original language.\\\"\" # @param {type:\"string\"}\n",
        "temperature = 0.6 #@param {type:\"slider\", min:0, max:1.0, step:0.1}\n",
        "# @markdown <font size=\"4\">Default prompt: </br>\n",
        "# @markdown ```You are a language expert.```</br>\n",
        "# @markdown ```Your task is to translate the input subtitle text, sentence by sentence, into the user specified target language.```</br>\n",
        "# @markdown ```Please utilize the context to improve the accuracy and quality of translation.```</br>\n",
        "# @markdown ```Please be aware that the input text could contain typos and grammar mistakes, utilize the context to correct the translation.```</br>\n",
        "# @markdown ```Please return only translated content and do not include the origin text.```</br>\n",
        "# @markdown ```Please do not use any punctuation around the returned text.```</br>\n",
        "# @markdown ```Please do not translate people's name and leave it as original language.```</br>\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import codecs\n",
        "import regex as re\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from google.colab import files\n",
        "from IPython.display import clear_output\n",
        "\n",
        "uploaded = files.upload()\n",
        "sub_name = list(uploaded.keys())[0]\n",
        "sub_basename = Path(sub_name).stem\n",
        "\n",
        "clear_output()\n",
        "\n",
        "!pip install -q -U google-generativeai\n",
        "!pip install pysubs2\n",
        "\n",
        "import google.generativeai as genai\n",
        "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
        "import pysubs2\n",
        "\n",
        "genai.configure(api_key=google_api_key)\n",
        "\n",
        "model = genai.GenerativeModel('gemini-pro')\n",
        "\n",
        "def translate(prompt, language, text, retry_times=0):\n",
        "        # print(text)\n",
        "        # self.rotate_key()\n",
        "        try:\n",
        "            completion = model.generate_content(prompt + \"target language :\" + language + \"text: \" + text, safety_settings={\n",
        "                    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
        "                    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
        "                    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
        "                    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
        "            })\n",
        "            t_text = (\n",
        "                completion.text\n",
        "            )\n",
        "            print(t_text)\n",
        "            return t_text\n",
        "        except Exception as e:\n",
        "            if re.search(r\"^429 POST|Remote end closed connection|Connection reset by peer\", str(e), flags=re.I) and retry_times < 6:\n",
        "                print(\"翻译接口请求过于频繁或被断开，将再次重试，重试次数: %d\" % (retry_times + 1))\n",
        "                print(\"The translation interface request is too frequent or disconnected. Will try again. Number of retries: %d\" % (retry_times + 1))\n",
        "                time.sleep(min(retry_times + 1, 3))\n",
        "                return translate(prompt, language, text, retry_times + 1)\n",
        "            else:\n",
        "                # Since Google API should not run into runtime error, this would be an unknown error\n",
        "                print(\"未知错误，用户可以尝试查看报错信息并在Repository里提交issue\")\n",
        "                print(\"Unknown Error, please check the error log and open an issue in the repository\")\n",
        "                return \">>>>> UnknownError\"\n",
        "class SubtitleTranslator():\n",
        "    def __init__(self, sub_src):\n",
        "        self.sub_src = sub_src\n",
        "        self.translations = []\n",
        "\n",
        "    def translate_by_line(self):\n",
        "        sub_trans = pysubs2.load(self.sub_src)\n",
        "        total_lines = len(sub_trans)\n",
        "        for line in tqdm(sub_trans,total = total_lines):\n",
        "            line_trans = translate(prompt, target_language, line.text)\n",
        "            line.text += (r'\\N'+ line_trans)\n",
        "            print(line_trans)\n",
        "            self.translations.append(line_trans)\n",
        "        return sub_trans, self.translations\n",
        "\n",
        "clear_output()\n",
        "\n",
        "if not google_api_key:\n",
        "    raise Exception(\n",
        "        \"Google Gemini API key not provided, please google how to obtain it\"\n",
        "    )\n",
        "\n",
        "t = SubtitleTranslator(sub_src=sub_name)\n",
        "\n",
        "translation, _, = t.translate_by_line()\n",
        "\n",
        "if output_format == 'ass':\n",
        "  translation.save(sub_basename + '_translation.ass')\n",
        "  files.download(sub_basename + '_translation.ass')\n",
        "elif output_format == 'srt':\n",
        "  translation.save(sub_basename + '_translation.srt')\n",
        "  files.download(sub_basename + '_translation.srt')\n",
        "\n",
        "print('双语字幕生成完毕 All done!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31uBTiJBrg0W"
      },
      "outputs": [],
      "source": [
        "#@title **【实验功能】Experimental Features:**\n",
        "\n",
        "# @markdown **Ollama AI文本翻译/Ollama AI Translation:**\n",
        "# @markdown **</br>**<font size=\"2\"> 使用Ollama来执行本地部署的LLM，想要免费使用AI翻译的用户可以执行以下单元格。\n",
        "# @markdown **</br>**阅读项目文档以了解更多。</font>\n",
        "# @markdown **</br>**<font size=\"2\"> Since Ollama provides the ability to deploy LLMs locally, the users that want to use free AI translations can execute the following blocks of code.\n",
        "# @markdown **</br>**Then generate bilingual subtitle files in same sub style.Read documentaion to learn more.</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgCsn0wLrg0W"
      },
      "outputs": [],
      "source": [
        "#@title **下载Ollama Library/Importing Ollama Library**\n",
        "\n",
        "!sudo apt update\n",
        "\n",
        "!sudo apt install -y pciutils\n",
        "\n",
        "!curl https://ollama.ai/install.sh | sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ug7kHQPLrg0W"
      },
      "outputs": [],
      "source": [
        "#@title **初始化Ollama Server/Starting Ollama Server**\n",
        "\n",
        "\n",
        "import threading\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "def run_ollama_serve():\n",
        "  subprocess.Popen([\"ollama\", \"serve\"])\n",
        "\n",
        "thread = threading.Thread(target=run_ollama_serve)\n",
        "thread.start()\n",
        "time.sleep(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7IO8aRWrg0W"
      },
      "outputs": [],
      "source": [
        "#@title **下载Ollama LLM/Pulling Ollama LLM**\n",
        "\n",
        "# @markdown **用户可以在这里选择想要部署的LLM**\n",
        "\n",
        "# @markdown **The user can choose the LLM type for the deployment here**\n",
        "\n",
        "model_type = \"deepseek-llm\"  # @param [\"llama3.2:3b\", \"deepseek-r1:7b\", \"deepseek-llm\"]\n",
        "\n",
        "!ollama pull $model_type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncdNZ_s4rg0X"
      },
      "outputs": [],
      "source": [
        "#@title **进行翻译/Translating The Subtitles**\n",
        "\n",
        "!pip install -U langchain-ollama\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_ollama.llms import OllamaLLM\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import codecs\n",
        "import regex as re\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from google.colab import files\n",
        "from IPython.display import clear_output\n",
        "\n",
        "uploaded = files.upload()\n",
        "sub_name = list(uploaded.keys())[0]\n",
        "sub_basename = Path(sub_name).stem\n",
        "\n",
        "clear_output()\n",
        "\n",
        "!pip install pysubs2\n",
        "\n",
        "import pysubs2\n",
        "\n",
        "output_format = \"ass\"  # @param [\"ass\",\"srt\"]\n",
        "\n",
        "target_language = 'zh-hans'# @param [\"zh-hans\",\"english\"]\n",
        "template = \"You are a language expert.Your task is to translate the input subtitle text, sentence by sentence, into {target_language}.However, please utilize the context to improve the accuracy and quality of translation.Please be aware that the input text could contain typos and grammar mistakes, utilize the context to correct the translation.Please return only translated content and do not include the origin text. Do not return your thinking process and only return the translated text. Please do not use any punctuation around the returned text.Please do not translate people's name and leave it as original language. Here is the text to translate: {text}\\\"\" # @param {type:\"string\"}\n",
        "\n",
        "# @markdown <font size=\"4\">Default prompt: </br>\n",
        "# @markdown ```You are a language expert.```</br>\n",
        "# @markdown ```Your task is to translate the input subtitle text, sentence by sentence, into {target_language}.```</br>\n",
        "# @markdown ```Please utilize the context to improve the accuracy and quality of translation.```</br>\n",
        "# @markdown ```Please be aware that the input text could contain typos and grammar mistakes, utilize the context to correct the translation.```</br>\n",
        "# @markdown ```Please return only translated content and do not include the origin text.```</br>\n",
        "# @markdown ```Do not return your thinking process and only return the translated text.```</br>\n",
        "# @markdown ```Please do not use any punctuation around the returned text.```</br>\n",
        "# @markdown ```Please do not translate people's name and leave it as original language.```</br>\n",
        "# @markdown ```Here is the text to translate: {text}```</br>\n",
        "\n",
        "llm = OllamaLLM(model=model_type)\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "chain = prompt | llm\n",
        "\n",
        "def translate(prompt, language, text):\n",
        "        # print(text)\n",
        "        # self.rotate_key()\n",
        "        t_text = chain.invoke({\"target_language\": language, \"text\": text})\n",
        "        print(t_text)\n",
        "        return t_text\n",
        "\n",
        "class SubtitleTranslator():\n",
        "    def __init__(self, sub_src):\n",
        "        self.sub_src = sub_src\n",
        "        self.translations = []\n",
        "\n",
        "    def translate_by_line(self):\n",
        "        sub_trans = pysubs2.load(self.sub_src)\n",
        "        total_lines = len(sub_trans)\n",
        "        for line in tqdm(sub_trans,total = total_lines):\n",
        "            line_trans = translate(prompt, target_language, line.text)\n",
        "            line.text += (r'\\N'+ line_trans)\n",
        "            print(line_trans)\n",
        "            self.translations.append(line_trans)\n",
        "        return sub_trans, self.translations\n",
        "\n",
        "clear_output()\n",
        "\n",
        "t = SubtitleTranslator(sub_src=sub_name)\n",
        "\n",
        "translation, _, = t.translate_by_line()\n",
        "\n",
        "if output_format == 'ass':\n",
        "  translation.save(sub_basename + '_translation.ass')\n",
        "  files.download(sub_basename + '_translation.ass')\n",
        "elif output_format == 'srt':\n",
        "  translation.save(sub_basename + '_translation.srt')\n",
        "  files.download(sub_basename + '_translation.srt')\n",
        "\n",
        "print('双语字幕生成完毕 All done!')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}